package scala
import main.scala.IrisHelper
import org.apache.hadoop.shaded.org.eclipse.jetty.websocket.common.frames.DataFrame
import org.apache.spark.mllib.linalg.Vector
import org.jpmml.evaluator.spark.TransformerBuilder;
import java.util.stream.Collectors.toList


import scala.collection.JavaConversions
import java.util.Arrays
//import org.apache.spark
import org.apache.spark.SparkConf
import org.apache.spark.mllib.linalg.{Vector, Vectors}
import org.apache.spark.sql.SparkSession
import org.jpmml.evaluator.LoadingModelEvaluatorBuilder

object IrisHelper {
  case class InputRecord(
                          `Sepal.Length`:Double,
                          `Sepal.Width`:Double,
                          `Petal.Length`:Double,
                          `Petal.Width`:Double
                        )
}

import org.tensorflow._
import scala.collection.JavaConverters._

object SpkJpmml {

  import IrisHelper._
  def main(args: Array[String]): Unit = {
    implicit val sparkSession = SparkSession
      .builder()
      .config(
        new SparkConf()
          .setAppName("DecisionTreeIris")
          .setMaster("local")
      ).getOrCreate()

    // prepare the input data
    val inputRdd = sparkSession.sparkContext.makeRDD(Seq(
      InputRecord(5.1, 3.5, 1.4, 0.2),
      InputRecord(5.8, 3.1, 4.8, 1.8),
      InputRecord(4.9, 3, 1.4, 0.2)

      //    InputRecord(5.1, 3.5, 1.4, 0.2),
      //    InputRecord(7, 3.2, 4.7, 1.4),
      //    InputRecord(6.3, 3.3, 6, 2.5)
    ))
    val inputData = sparkSession.createDataFrame(inputRdd)

    // load the pmml
    val pmml = getClass.getClassLoader.getResourceAsStream("GBDT.pmml")

    //create the evaluator
    val evaluator = new LoadingModelEvaluatorBuilder()
      .load(pmml)
      .build()

    val targetField  =evaluator.getTargetFields.toString
    println(targetField)

    val outputField  =evaluator.getOutputFields.toString
    println(outputField)
    //create the transformer 
    var pmmlTransformer = new TransformerBuilder(evaluator)
      .withTargetCols()
      .withOutputCols()
      .exploded(false) // This is it!!!
      .build()

    sparkSession.sql("set spark.sql.legacy.allowUntypedScalaUDF=true")
    var resultDs = pmmlTransformer.transform(inputData)//inputData
    resultDs.show

    resultDs = resultDs.select("pmml")
    resultDs.show
    resultDs.toDF("y")
    resultDs.show()
    val a = resultDs.show(0)
    println("aaa = ", a)

  }

}
